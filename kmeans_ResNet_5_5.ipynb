{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_file = \"h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\DNDF_merge.tif\"\n",
    "results.to_csv(\"h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\202404_DNDF_cluster_resnet50_5_5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "# Load the TIFF file\n",
    "tiff_file = \"h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\DNDF_merge.tif\"\n",
    "\n",
    "# Open the file with rasterio\n",
    "with rasterio.open(tiff_file) as src:\n",
    "    # Print general metadata\n",
    "    print(f\"Width: {src.width}\")\n",
    "    print(f\"Height: {src.height}\")\n",
    "    print(f\"Number of bands: {src.count}\")\n",
    "    print(f\"Data type: {src.dtypes}\")\n",
    "    print(f\"CRS: {src.crs}\")\n",
    "    print(f\"Transform: {src.transform}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\.conda\\envs\\RS\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\.conda\\envs\\RS\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\user\\.conda\\envs\\RS\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "\n",
    "# Check if a GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the TIFF file\n",
    "# tiff_file = \"h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\DNDF_merge.tif\"\n",
    "tiff_file = \"h:\\\\Yehmh\\\\DNDF\\\\202406_DNDF\\\\202406DNDFmerge.tif\"\n",
    "with rasterio.open(tiff_file) as src:\n",
    "    # Metadata\n",
    "    transform = src.transform\n",
    "    width = src.width\n",
    "    height = src.height\n",
    "\n",
    "    # Calculate pixel size (in meters) based on the resolution\n",
    "    pixel_width = abs(transform[0])  # Pixel width in meters\n",
    "    pixel_height = abs(transform[4])  # Pixel height in meters\n",
    "\n",
    "    # Calculate the number of pixels that correspond to 5 meters\n",
    "    crop_width_px = int(5 / pixel_width)\n",
    "    crop_height_px = int(5 / pixel_height)\n",
    "\n",
    "    bands = src.read([1, 2, 3])  # Read only the RGB bands (1, 2, 3)\n",
    "\n",
    "# Pretrained ResNet50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])  # Remove the final classification layer\n",
    "model = model.to(device)  # Move model to GPU if available\n",
    "model.eval()\n",
    "\n",
    "# Transform for ResNet-50 input\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "features = []\n",
    "centers = []\n",
    "\n",
    "# Iterate over the TIFF image to crop based on the calculated pixel dimensions\n",
    "for i in range(0, width, crop_width_px):\n",
    "    for j in range(0, height, crop_height_px):\n",
    "        # Crop the image\n",
    "        crop = bands[:, j:j+crop_height_px, i:i+crop_width_px]\n",
    "\n",
    "        # Check for zero-value RGB pixels\n",
    "        if np.all(crop == 0):\n",
    "            continue  # Skip crops with all 0-value pixels\n",
    "\n",
    "        # Drop the alpha band (no alpha band in this case, but we keep RGB)\n",
    "        crop = crop[:3]  # Ensure only RGB channels\n",
    "\n",
    "        # Convert the crop to uint8\n",
    "        crop = np.transpose(crop, (1, 2, 0)).astype(np.uint8)  # Change dtype to uint8\n",
    "\n",
    "        # Transform and extract features\n",
    "        input_tensor = preprocess(crop).unsqueeze(0).to(device)  # Move tensor to GPU if available\n",
    "        with torch.no_grad():\n",
    "            feature = model(input_tensor).squeeze().cpu().numpy()  # Move output back to CPU\n",
    "\n",
    "        # Store the features and the center coordinates\n",
    "        features.append(feature)\n",
    "        center_coord = (i + crop_width_px // 2, j + crop_height_px // 2)\n",
    "        centers.append(src.transform * center_coord)  # Convert to TM2 coordinates\n",
    "\n",
    "# Cluster the images using k-means\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(features)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Save results to CSV\n",
    "results = pd.DataFrame({\n",
    "    \"x_coord\": [coord[0] for coord in centers],\n",
    "    \"y_coord\": [coord[1] for coord in centers],\n",
    "    \"cluster\": labels\n",
    "})\n",
    "# results.to_csv(\"h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\202404_DNDF_cluster_resnet50_5_5.csv\", index=False)\n",
    "results.to_csv(\"h:\\\\Yehmh\\\\DNDF\\\\202406_DNDF\\\\202406DNDFmerge_cluster_resnet50_5_5_10.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "# Initialize the model\n",
    "def initialize_model(device):\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model = torch.nn.Sequential(*list(model.children())[:-1])  # Remove the final classification layer\n",
    "    model = model.to(device)  # Move model to GPU if available\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Extract features from the image\n",
    "def extract_features_from_image(tiff_file, crop_size_meters, model, device):\n",
    "    with rasterio.open(tiff_file) as src:\n",
    "        transform = src.transform\n",
    "        width = src.width\n",
    "        height = src.height\n",
    "        crs = src.crs\n",
    "\n",
    "        pixel_width = abs(transform[0])  # Pixel width in meters\n",
    "        pixel_height = abs(transform[4])  # Pixel height in meters\n",
    "\n",
    "        crop_width_px = int(crop_size_meters / pixel_width)\n",
    "        crop_height_px = int(crop_size_meters / pixel_height)\n",
    "\n",
    "        bands = src.read([1, 2, 3])  # Read only the RGB bands\n",
    "\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    features = []\n",
    "    centers = []\n",
    "    geometries = []\n",
    "\n",
    "    for i in range(0, width, crop_width_px):\n",
    "        for j in range(0, height, crop_height_px):\n",
    "            crop = bands[:, j:j+crop_height_px, i:i+crop_width_px]\n",
    "\n",
    "            if np.all(crop == 0):\n",
    "                continue  # Skip crops with all 0-value pixels\n",
    "\n",
    "            crop = np.transpose(crop[:3], (1, 2, 0)).astype(np.uint8)  # Ensure only RGB channels and convert dtype to uint8\n",
    "\n",
    "            input_tensor = preprocess(crop).unsqueeze(0).to(device)  # Move tensor to GPU if available\n",
    "            with torch.no_grad():\n",
    "                feature = model(input_tensor).squeeze().cpu().numpy()  # Move output back to CPU\n",
    "\n",
    "            features.append(feature)\n",
    "            center_coord = (i + crop_width_px // 2, j + crop_height_px // 2)\n",
    "            centers.append(src.transform * center_coord)  # Convert to TM2 coordinates\n",
    "\n",
    "            minx, miny = src.transform * (i, j)\n",
    "            maxx, maxy = src.transform * (i + crop_width_px, j + crop_height_px)\n",
    "            geometries.append(box(minx, miny, maxx, maxy))\n",
    "\n",
    "    return features, centers, geometries, crs, transform, height, width\n",
    "\n",
    "# Perform clustering on the features\n",
    "def perform_clustering(features, n_clusters=5):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(features)\n",
    "    return kmeans.labels_\n",
    "\n",
    "# Save the results as a shapefile\n",
    "def save_shapefile(geometries, labels, crs, shapefile_path):\n",
    "    gdf = gpd.GeoDataFrame({\n",
    "        'geometry': geometries,\n",
    "        'cluster': labels\n",
    "    }, crs=crs)\n",
    "    gdf.to_file(shapefile_path)\n",
    "\n",
    "# Save the clustered labels as a TIFF file\n",
    "def save_tiff(labels, transform, height, width, crs, tiff_file_path):\n",
    "    labels_image = np.zeros((height, width), dtype=np.int32)\n",
    "    labels_image[:len(labels)] = labels.reshape(-1, 1)  # Assuming labels length fits into image dimensions\n",
    "\n",
    "    with rasterio.open(\n",
    "        tiff_file_path,\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=height,\n",
    "        width=width,\n",
    "        count=1,\n",
    "        dtype=rasterio.int32,\n",
    "        crs=crs,\n",
    "        transform=transform,\n",
    "    ) as dst:\n",
    "        dst.write(labels_image, 1)\n",
    "\n",
    "# Save the clustering results as a CSV file\n",
    "def save_csv(centers, labels, csv_file_path):\n",
    "    results = pd.DataFrame({\n",
    "        \"x_coord\": [coord[0] for coord in centers],\n",
    "        \"y_coord\": [coord[1] for coord in centers],\n",
    "        \"cluster\": labels\n",
    "    })\n",
    "    results.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Main function to process the image\n",
    "def process_image(tiff_file, crop_size_meters, shapefile_path, tiff_file_path, csv_file_path, n_clusters=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = initialize_model(device)\n",
    "    \n",
    "    features, centers, geometries, crs, transform, height, width = extract_features_from_image(\n",
    "        tiff_file, crop_size_meters, model, device\n",
    "    )\n",
    "    labels = perform_clustering(features, n_clusters)\n",
    "\n",
    "    save_shapefile(geometries, labels, crs, shapefile_path)\n",
    "    save_tiff(labels, transform, height, width, crs, tiff_file_path)\n",
    "    save_csv(centers, labels, csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 7 9 ... 9 0 9]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (175255,1) into shape (49597,44910)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(shapefile_path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m save_shapefile(geometries, labels, crs, shapefile_path)\n\u001b[1;32m---> 16\u001b[0m \u001b[43msave_tiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtiff_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m save_csv(centers, labels, csv_file_path)\n",
      "Cell \u001b[1;32mIn[5], line 86\u001b[0m, in \u001b[0;36msave_tiff\u001b[1;34m(labels, transform, height, width, crs, tiff_file_path)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_tiff\u001b[39m(labels, transform, height, width, crs, tiff_file_path):\n\u001b[0;32m     85\u001b[0m     labels_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((height, width), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m---> 86\u001b[0m     \u001b[43mlabels_image\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Assuming labels length fits into image dimensions\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m rasterio\u001b[38;5;241m.\u001b[39mopen(\n\u001b[0;32m     89\u001b[0m         tiff_file_path,\n\u001b[0;32m     90\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m         transform\u001b[38;5;241m=\u001b[39mtransform,\n\u001b[0;32m     98\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m dst:\n\u001b[0;32m     99\u001b[0m         dst\u001b[38;5;241m.\u001b[39mwrite(labels_image, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (175255,1) into shape (49597,44910)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "shapefile_path = \"h:\\\\Yehmh\\\\DNDF\\\\202405_DNDF\\\\5_5_cluster\\\\DNDF_merge_grid_5_5.shp\"\n",
    "tiff_file_path = \"h:\\\\Yehmh\\\\DNDF\\\\202405_DNDF\\\\5_5_cluster\\\\DNDF_merge_clustered.tif\"\n",
    "csv_file_path = \"h:\\\\Yehmh\\\\DNDF\\\\202405_DNDF\\\\5_5_cluster\\\\DNDF_mergee_cluster_resnet50_5_5.csv\"\n",
    "\n",
    "crop_size_meters = 5\n",
    "\n",
    "features, centers, geometries, crs, transform, height, width = extract_features_from_image(\n",
    "        tiff_file, crop_size_meters, model, device\n",
    "    )\n",
    "\n",
    "os.makedirs(os.path.dirname(shapefile_path), exist_ok=True)\n",
    "\n",
    "save_shapefile(geometries, labels, crs, shapefile_path)\n",
    "save_tiff(labels, transform, height, width, crs, tiff_file_path)\n",
    "save_csv(centers, labels, csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\.conda\\envs\\RS\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "ename": "DriverIOError",
     "evalue": "Failed to create file h:\\Yehmh\\DNDF\\202405_DNDF\\5_5_cluster\\DNDF_merge_grid_5_5.shp: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCPLE_AppDefinedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mfiona\\\\ogrext.pyx:1239\u001b[0m, in \u001b[0;36mfiona.ogrext.WritingSession.start\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mfiona\\\\ogrext.pyx:1240\u001b[0m, in \u001b[0;36mfiona.ogrext.WritingSession.start\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mfiona\\\\_err.pyx:291\u001b[0m, in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCPLE_AppDefinedError\u001b[0m: Failed to create file h:\\Yehmh\\DNDF\\202405_DNDF\\5_5_cluster\\DNDF_merge_grid_5_5.shp: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDriverIOError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m tiff_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mYehmh\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDNDF\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m202405_DNDF\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m5_5_cluster\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDNDF_merge_clustered.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mYehmh\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDNDF\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m202405_DNDF\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m5_5_cluster\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDNDF_mergee_cluster_resnet50_5_5.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtiff_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop_size_meters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshapefile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshapefile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtiff_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtiff_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcsv_file_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 120\u001b[0m, in \u001b[0;36mprocess_image\u001b[1;34m(tiff_file, crop_size_meters, shapefile_path, tiff_file_path, csv_file_path, n_clusters)\u001b[0m\n\u001b[0;32m    115\u001b[0m features, centers, geometries, crs, transform, height, width \u001b[38;5;241m=\u001b[39m extract_features_from_image(\n\u001b[0;32m    116\u001b[0m     tiff_file, crop_size_meters, model, device\n\u001b[0;32m    117\u001b[0m )\n\u001b[0;32m    118\u001b[0m labels \u001b[38;5;241m=\u001b[39m perform_clustering(features, n_clusters)\n\u001b[1;32m--> 120\u001b[0m \u001b[43msave_shapefile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeometries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshapefile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m save_tiff(labels, transform, height, width, crs, tiff_file_path)\n\u001b[0;32m    122\u001b[0m save_csv(centers, labels, csv_file_path)\n",
      "Cell \u001b[1;32mIn[5], line 81\u001b[0m, in \u001b[0;36msave_shapefile\u001b[1;34m(geometries, labels, crs, shapefile_path)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_shapefile\u001b[39m(geometries, labels, crs, shapefile_path):\n\u001b[0;32m     77\u001b[0m     gdf \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame({\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m: geometries,\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m: labels\n\u001b[0;32m     80\u001b[0m     }, crs\u001b[38;5;241m=\u001b[39mcrs)\n\u001b[1;32m---> 81\u001b[0m     \u001b[43mgdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshapefile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\RS\\lib\\site-packages\\geopandas\\geodataframe.py:1263\u001b[0m, in \u001b[0;36mGeoDataFrame.to_file\u001b[1;34m(self, filename, driver, schema, index, **kwargs)\u001b[0m\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Write the ``GeoDataFrame`` to a file.\u001b[39;00m\n\u001b[0;32m   1173\u001b[0m \n\u001b[0;32m   1174\u001b[0m \u001b[38;5;124;03mBy default, an ESRI shapefile is written, but any OGR data source\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1259\u001b[0m \n\u001b[0;32m   1260\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _to_file\n\u001b[1;32m-> 1263\u001b[0m \u001b[43m_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\RS\\lib\\site-packages\\geopandas\\io\\file.py:572\u001b[0m, in \u001b[0;36m_to_file\u001b[1;34m(df, filename, driver, schema, index, mode, crs, engine, **kwargs)\u001b[0m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 572\u001b[0m     \u001b[43m_to_file_fiona\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    574\u001b[0m     _to_file_pyogrio(df, filename, driver, schema, crs, mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\RS\\lib\\site-packages\\geopandas\\io\\file.py:598\u001b[0m, in \u001b[0;36m_to_file_fiona\u001b[1;34m(df, filename, driver, schema, crs, mode, **kwargs)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m crs:\n\u001b[0;32m    597\u001b[0m     crs_wkt \u001b[38;5;241m=\u001b[39m crs\u001b[38;5;241m.\u001b[39mto_wkt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWKT1_GDAL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 598\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfiona\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs_wkt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs_wkt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m colxn:\n\u001b[0;32m    601\u001b[0m     colxn\u001b[38;5;241m.\u001b[39mwriterecords(df\u001b[38;5;241m.\u001b[39miterfeatures())\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\RS\\lib\\site-packages\\fiona\\env.py:457\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    454\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\RS\\lib\\site-packages\\fiona\\__init__.py:331\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[0;32m    320\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[0;32m    321\u001b[0m         path,\n\u001b[0;32m    322\u001b[0m         mode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    329\u001b[0m     )\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 331\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m \u001b[43mCollection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43menabled_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menabled_drivers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcrs_wkt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs_wkt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unsupported_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_unsupported_drivers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode string must be one of \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\.conda\\envs\\RS\\lib\\site-packages\\fiona\\collection.py:246\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[1;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, include_fields, wkt_version, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m WritingSession()\n\u001b[1;32m--> 246\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mfiona\\\\ogrext.pyx:1248\u001b[0m, in \u001b[0;36mfiona.ogrext.WritingSession.start\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDriverIOError\u001b[0m: Failed to create file h:\\Yehmh\\DNDF\\202405_DNDF\\5_5_cluster\\DNDF_merge_grid_5_5.shp: No such file or directory"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "tiff_file = \"h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\DNDF_merge.tif\"\n",
    "shapefile_path = \"h:\\\\Yehmh\\\\DNDF\\\\202405_DNDF\\\\5_5_cluster\\\\DNDF_merge_grid_5_5.shp\"\n",
    "tiff_file_path = \"h:\\\\Yehmh\\\\DNDF\\\\202405_DNDF\\\\5_5_cluster\\\\DNDF_merge_clustered.tif\"\n",
    "csv_file_path = \"h:\\\\Yehmh\\\\DNDF\\\\202405_DNDF\\\\5_5_cluster\\\\DNDF_mergee_cluster_resnet50_5_5.csv\"\n",
    "\n",
    "process_image(tiff_file, crop_size_meters=5, shapefile_path=shapefile_path, tiff_file_path=tiff_file_path, csv_file_path=csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import h5py\n",
    "\n",
    "# Save features, labels, and centers to a pickle file\n",
    "with open(\"h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\intermediate_clustering_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\"features\": features, \"labels\": labels, \"centers\": centers}, f)\n",
    "\n",
    "with h5py.File(\"h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\intermediate_clustering_results.h5\", \"w\") as f:\n",
    "    f.create_dataset('features', data=features)\n",
    "    f.create_dataset('labels', data=labels)\n",
    "    f.create_dataset('centers', data=centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\.conda\\envs\\RS\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File(\"h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\intermediate_clustering_results.h5\", \"r\") as f:\n",
    "    features = f['features'][:]\n",
    "    labels = f['labels'][:]\n",
    "    centers = f['centers'][:]\n",
    "\n",
    "target_cluster = 3  # The cluster you want to re-cluster\n",
    "filtered_features = [feat for feat, label in zip(features, labels) if label == target_cluster]\n",
    "filtered_centers = [center for center, label in zip(centers, labels) if label == target_cluster]\n",
    "\n",
    "# Re-cluster the filtered features\n",
    "new_kmeans = KMeans(n_clusters=2, random_state=42).fit(filtered_features)\n",
    "new_labels = new_kmeans.labels_\n",
    "\n",
    "# Save the new cluster labels for further analysis\n",
    "results = pd.DataFrame({\n",
    "    \"x_coord\": [coord[0] for coord in filtered_centers],\n",
    "    \"y_coord\": [coord[1] for coord in filtered_centers],\n",
    "    \"new_cluster\": new_labels\n",
    "})\n",
    "results.to_csv(f\"h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\202404_DNDF_reclustered_cluster_{target_cluster}_2.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
