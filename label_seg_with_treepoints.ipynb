{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liqu_fo 0 101_0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'box' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 94\u001b[0m\n\u001b[0;32m     91\u001b[0m pickle_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mYehmh\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDNDF\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m202404_DNDF\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mpickles\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtransects_seg_species6_patches_and_labels_5.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Process and save patches_and_labels to a pickle file\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m patches_and_labels \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_shapefile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshapefile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtif_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(pickle_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     96\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(patches_and_labels, f)\n",
      "Cell \u001b[1;32mIn[17], line 82\u001b[0m, in \u001b[0;36mprocess_shapefile\u001b[1;34m(shapefile_path, tif_file_path)\u001b[0m\n\u001b[0;32m     79\u001b[0m ID \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransect\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(label, fid, ID)\n\u001b[1;32m---> 82\u001b[0m patch \u001b[38;5;241m=\u001b[39m \u001b[43mextract_polygon_patch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolygon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m patch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m     patches_and_labels\u001b[38;5;241m.\u001b[39mappend((np\u001b[38;5;241m.\u001b[39marray(patch), label, ID))  \u001b[38;5;66;03m# Store patch, label, and FID\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 20\u001b[0m, in \u001b[0;36mextract_polygon_patch\u001b[1;34m(polygon, image_data, src_transform)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Get the bounds of the polygon\u001b[39;00m\n\u001b[0;32m     19\u001b[0m tile_bounds \u001b[38;5;241m=\u001b[39m polygon\u001b[38;5;241m.\u001b[39mbounds  \u001b[38;5;66;03m# Automatically get bounds from the polygon\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m cropped_polygon \u001b[38;5;241m=\u001b[39m \u001b[43mcrop_polygon_to_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolygon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile_bounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Check if the cropped polygon is valid before proceeding\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cropped_polygon\u001b[38;5;241m.\u001b[39mis_empty:\n",
      "Cell \u001b[1;32mIn[17], line 12\u001b[0m, in \u001b[0;36mcrop_polygon_to_tile\u001b[1;34m(polygon, tile_bounds)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcrop_polygon_to_tile\u001b[39m(polygon, tile_bounds):\n\u001b[0;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Crop the polygon to the tile bounds.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     tile_box \u001b[38;5;241m=\u001b[39m \u001b[43mbox\u001b[49m(\u001b[38;5;241m*\u001b[39mtile_bounds)  \u001b[38;5;66;03m# Create a bounding box for the tile\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     cropped_polygon \u001b[38;5;241m=\u001b[39m polygon\u001b[38;5;241m.\u001b[39mintersection(tile_box)  \u001b[38;5;66;03m# Intersect with the tile box\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cropped_polygon\n",
      "\u001b[1;31mNameError\u001b[0m: name 'box' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "import rasterio\n",
    "from rasterio.features import geometry_mask\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def crop_polygon_to_tile(polygon, tile_bounds):\n",
    "    \"\"\"Crop the polygon to the tile bounds.\"\"\"\n",
    "    tile_box = box(*tile_bounds)  # Create a bounding box for the tile\n",
    "    cropped_polygon = polygon.intersection(tile_box)  # Intersect with the tile box\n",
    "    return cropped_polygon\n",
    "\n",
    "def extract_polygon_patch(polygon, image_data, src_transform):\n",
    "    \"\"\"Extract image patch within a polygon.\"\"\"\n",
    "    # Get the bounds of the polygon\n",
    "    tile_bounds = polygon.bounds  # Automatically get bounds from the polygon\n",
    "    cropped_polygon = crop_polygon_to_tile(polygon, tile_bounds)\n",
    "    \n",
    "    # Check if the cropped polygon is valid before proceeding\n",
    "    if not cropped_polygon.is_empty:\n",
    "        mask = geometry_mask([mapping(cropped_polygon)], transform=src_transform, invert=True, out_shape=(image_data.shape[1], image_data.shape[2]))\n",
    "        masked_data = np.zeros_like(image_data[:3])\n",
    "        \n",
    "        for i in range(3):\n",
    "            masked_data[i] = image_data[i] * mask\n",
    "            \n",
    "        bounds = cropped_polygon.bounds\n",
    "        window = rasterio.windows.from_bounds(*bounds, transform=src_transform)\n",
    "        row_off = int(window.row_off)\n",
    "        col_off = int(window.col_off)\n",
    "        height = int(window.height)\n",
    "        width = int(window.width)\n",
    "        patch = masked_data[:, row_off:row_off + height, col_off:col_off + width]\n",
    "        patch = np.moveaxis(patch, 0, -1)\n",
    "        patch = Image.fromarray(patch.astype(np.uint8))\n",
    "        \n",
    "        # Plot the image and mask side by side\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Raster image with cropped polygon overlay\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image_data[0], cmap='gray', alpha=0.5)  # Show the first band of the image\n",
    "        plt.gca().add_patch(plt.Polygon(list(cropped_polygon.exterior.coords), fill=None, edgecolor='red', linewidth=2, label='Cropped Polygon'))\n",
    "        plt.title(\"Raster Image with Cropped Polygon Overlay\")\n",
    "        plt.legend()\n",
    "        \n",
    "        # Mask visualization\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(mask, cmap='gray', alpha=0.5)  # Show the mask\n",
    "        plt.title(\"Mask Visualization\")\n",
    "        plt.colorbar(label='Mask Value')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return patch\n",
    "    else:\n",
    "        # Return None or handle the case where the polygon is empty\n",
    "        print(\"Cropped polygon is empty.\")\n",
    "        return None\n",
    "\n",
    "def process_shapefile(shapefile_path, tif_file_path):\n",
    "    \"\"\"Process shapefile to extract patches, labels, and FIDs.\"\"\"\n",
    "    polygons = gpd.read_file(shapefile_path)\n",
    "    patches_and_labels = []\n",
    "    \n",
    "    with rasterio.open(tif_file_path) as src:\n",
    "        image_data = src.read()\n",
    "        src_transform = src.transform\n",
    "\n",
    "    for idx, row in polygons.iterrows():\n",
    "        polygon = row.geometry\n",
    "        label = row['label']\n",
    "        fid = int(row['FID'])  # Extract FID value\n",
    "        transect = int(row['transect'])\n",
    "        ID = f\"{transect}_{fid}\"\n",
    "        print(label, fid, ID)\n",
    "\n",
    "        patch = extract_polygon_patch(polygon, image_data, src_transform)\n",
    "        if patch is not None:\n",
    "            patches_and_labels.append((np.array(patch), label, ID))  # Store patch, label, and FID\n",
    "        \n",
    "    return patches_and_labels\n",
    "\n",
    "# Example usage\n",
    "shapefile_path = 'h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\transects_seg_labeled\\\\transects_seg_species6.shp'\n",
    "tif_file_path = 'h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\DNDF_merge.tif'\n",
    "pickle_file_path = 'h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\pickles\\\\transects_seg_species6_patches_and_labels_5.pkl'\n",
    "\n",
    "# Process and save patches_and_labels to a pickle file\n",
    "patches_and_labels = process_shapefile(shapefile_path, tif_file_path)\n",
    "with open(pickle_file_path, 'wb') as f:\n",
    "    pickle.dump(patches_and_labels, f)\n",
    "\n",
    "print(\"patches_and_labels saved to patches_and_labels.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FID transect                                           geometry\n",
      "0  0.0      101  POLYGON ((292240.215 2612874.048, 292240.677 2...\n",
      "1  1.0      101  POLYGON ((292185.804 2612874.915, 292185.862 2...\n",
      "2  2.0      101  POLYGON ((292245.356 2612864.694, 292245.472 2...\n",
      "3  3.0      101  POLYGON ((292239.753 2612910.368, 292240.331 2...\n",
      "4  4.0      101  POLYGON ((292193.948 2612866.715, 292194.006 2...\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load the shapefile\n",
    "shapefile_path = 'h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\seg_merged\\\\merged_seg_masks_name.shp'\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Print the attribute table\n",
    "print(gdf.head())  # Prints the first 5 rows of the attribute table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "# Load the polygons shapefile\n",
    "polygons = gpd.read_file('h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\seg_merged\\\\merged_seg_masks_name.shp')\n",
    "\n",
    "# Load the CSV file\n",
    "csv_data = pd.read_csv('h:\\\\Yehmh\\\\DNDF\\\\DNDF_tree_survey_2023_rotated.csv')\n",
    "\n",
    "# Filter out points where the \"Stem\" value is not 0\n",
    "csv_data = csv_data[csv_data['Stem'] == 0]\n",
    "\n",
    "# Convert the filtered CSV data to a GeoDataFrame using TWD97_X and TWD97_Y\n",
    "csv_gdf = gpd.GeoDataFrame(csv_data, geometry=gpd.points_from_xy(csv_data.TWD97_X, csv_data.TWD97_Y))\n",
    "\n",
    "# Ensure the coordinate system matches between polygons and points (TWD97)\n",
    "csv_gdf.set_crs(epsg=3826, inplace=True)  # EPSG:3826 is the code for TWD97 TM2\n",
    "polygons.to_crs(epsg=3826, inplace=True)\n",
    "\n",
    "# Buffer polygons by 1 meter for the surrounding area check\n",
    "polygons_buffered = polygons.copy()\n",
    "polygons_buffered['geometry'] = polygons_buffered.geometry.buffer(1)\n",
    "\n",
    "# Function to determine the label for each polygon\n",
    "def label_polygon(polygon, buffered_polygon, points):\n",
    "    within_polygon = points[points.within(polygon)]\n",
    "    around_polygon = points[points.within(buffered_polygon)]\n",
    "    \n",
    "    # Combine points within and around the polygon\n",
    "    combined_points = pd.concat([within_polygon, around_polygon]).drop_duplicates()\n",
    "    \n",
    "    if combined_points.empty:\n",
    "        return None\n",
    "    \n",
    "    species_count = combined_points['CSP'].value_counts()\n",
    "    top_species = species_count.index[0]\n",
    "    max_dbh_species = combined_points.loc[combined_points['DBH'].idxmax()]['CSP']\n",
    "    \n",
    "    # If one species is the majority and also the largest DBH, label it as such\n",
    "    if species_count.index[0] == max_dbh_species:\n",
    "        return max_dbh_species\n",
    "    \n",
    "    # If counts are equal and max_dbh_species is among the top two, return max_dbh_species\n",
    "    if len(species_count) > 1 and species_count.iloc[0] == species_count.iloc[1]:\n",
    "        if max_dbh_species in top_species:\n",
    "            return max_dbh_species\n",
    "\n",
    "    # Return the top species and the max DBH species\n",
    "    return ','.join([top_species, max_dbh_species])\n",
    "\n",
    "# Apply the labeling function to each polygon\n",
    "polygons['label'] = polygons.apply(lambda row: label_polygon(row['geometry'], \n",
    "                                                              polygons_buffered.loc[row.name, 'geometry'], \n",
    "                                                              csv_gdf), axis=1)\n",
    "\n",
    "# Drop polygons without labels\n",
    "labeled_polygons = polygons.dropna(subset=['label'])\n",
    "\n",
    "# Save the labeled polygons to a new shapefile\n",
    "labeled_polygons.to_file('h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\transects_seg_labeled\\\\transects_seg_labeled_name.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load the labeled polygons shapefile\n",
    "labeled_polygons = gpd.read_file('h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\transects_seg_labeled\\\\transects_seg_labeled_name.shp')\n",
    "\n",
    "# Filter polygons that have only one species in the label\n",
    "single_species_polygons = labeled_polygons[labeled_polygons['label'].apply(lambda x: ',' not in x)]\n",
    "\n",
    "# Filter polygons that have two species in the label\n",
    "two_species_polygons = labeled_polygons[labeled_polygons['label'].apply(lambda x: ',' in x)]\n",
    "\n",
    "# Save the single species polygons to a new shapefile\n",
    "single_species_polygons.to_file('h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\transects_seg_labeled\\\\transects_seg_labeled_sure_name.shp')\n",
    "\n",
    "# Save the two species polygons to a new shapefile\n",
    "two_species_polygons.to_file('h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\transects_seg_labeled\\\\transects_seg_labeled_unsure_name.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered shapefile saved to h:\\Yehmh\\DNDF\\202404_DNDF\\transects_seg_labeled\\transects_seg_species6.shp\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load the labeled polygons shapefile\n",
    "labeled_polygons = gpd.read_file('h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\transects_seg_labeled\\\\transects_seg_labeled_name.shp')\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Define the labels you want to keep\n",
    "labels_to_keep = ['Bisc_ja', 'Liqu_fo', 'Cinn_bu', 'Zelk_se', 'Mach_zu', 'Frax_gr']\n",
    "\n",
    "# Filter the GeoDataFrame to only include the specified labels\n",
    "filtered_gdf = gdf[gdf['label'].isin(labels_to_keep)]\n",
    "\n",
    "# Save the filtered GeoDataFrame to a new shapefile\n",
    "filtered_shapefile_path = 'h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\transects_seg_labeled\\\\transects_seg_species6.shp'  # Update this with the desired output path\n",
    "filtered_gdf.to_file(filtered_shapefile_path)\n",
    "\n",
    "print(f\"Filtered shapefile saved to {filtered_shapefile_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Plot  tree_counts  tree_counts_dbh10up  total_count  filtered_count\n",
      "0    68          350                  154           67              64\n",
      "1    81          246                  169           59              56\n",
      "2   126          243                  106           42              42\n",
      "3    70          241                  103           35              31\n",
      "4    79          226                  127           49              47\n",
      "5    41          221                  119           45              42\n",
      "6    12          207                  156           24              23\n",
      "7   101          182                  131           66              65\n",
      "8    94          164                  117           55              54\n",
      "9    16          151                   83           43              42\n",
      "10   46          147                  106           35              35\n",
      "11  112          146                   81           49              48\n",
      "12   98          128                   84           54              53\n",
      "13   86          121                  101           33              32\n",
      "14   31          113                   68           40              39\n",
      "15  140           61                   42            4               4\n",
      "Files merged successfully!\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "shapefile_path = 'h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\transects_seg_labeled\\\\transects_seg_labeled_name.shp'\n",
    "csv_data_path = 'h:\\\\Yehmh\\\\DNDF\\\\DNDF_tree_survey_2023_rotated.csv'\n",
    "output_csv_path = 'h:\\\\Yehmh\\\\DNDF\\\\202404_DNDF\\\\transects_seg_labeled\\\\transects_polygon_counts.csv'\n",
    "\n",
    "# Read files\n",
    "merged_gdf = gpd.read_file(shapefile_path)\n",
    "csv_data = pd.read_csv(csv_data_path)\n",
    "\n",
    "# Calculate polygon areas and filter by area > 2\n",
    "merged_gdf['area'] = merged_gdf.geometry.area\n",
    "filtered_gdf = merged_gdf[merged_gdf['area'] > 2]\n",
    "\n",
    "# Count total and filtered polygons by transect\n",
    "polygon_counts = merged_gdf['transect'].value_counts().rename(\"total_count\").to_frame()\n",
    "polygon_counts['filtered_count'] = filtered_gdf['transect'].value_counts()\n",
    "\n",
    "# Load and filter tree data\n",
    "csv_data = csv_data[csv_data['Stem'] == 0]\n",
    "tree_counts = csv_data['Plot'].value_counts().rename('tree_counts').to_frame()\n",
    "tree_counts['tree_counts_dbh10up'] = csv_data[csv_data['DBH'] > 10]['Plot'].value_counts()\n",
    "\n",
    "# Ensure the 'Plot' column is of type string in both DataFrames\n",
    "tree_counts.index = tree_counts.index.astype(str)\n",
    "polygon_counts.index = polygon_counts.index.astype(str)\n",
    "\n",
    "# Rename 'transect' column to 'Plot' in polygon_counts to match tree_counts DataFrame\n",
    "polygon_counts = polygon_counts.rename_axis('Plot').reset_index()\n",
    "\n",
    "# Merge DataFrames\n",
    "merged_data = tree_counts.merge(polygon_counts, on='Plot', how='outer').fillna(0)\n",
    "print(merged_data)\n",
    "\n",
    "# Save the result to a CSV file\n",
    "# merged_data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(\"Files merged successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RS2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
