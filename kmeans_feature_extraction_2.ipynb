{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.models import Model\n",
    "\n",
    "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins, [0, 180, 0, 256, 0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "    return hist.flatten()\n",
    "\n",
    "def extract_deep_features(image_path, model):\n",
    "    image = load_img(image_path, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = preprocess_input(image)\n",
    "    features = model.predict(image)\n",
    "    return features.flatten()\n",
    "\n",
    "# Load VGG16 model + higher level layers\n",
    "base_model = VGG16(weights='imagenet')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)\n",
    "\n",
    "# Example: Extract features from images in a folder\n",
    "image_folder = 'h:\\\\Yehmh\\\\DNDF\\\\101_1_focus\\\\202404_101_seg_images_known'\n",
    "color_features = []\n",
    "deep_features = []\n",
    "image_paths = []\n",
    "\n",
    "for image_name in os.listdir(image_folder):\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    color_hist = extract_color_histogram(image)\n",
    "    deep_feat = extract_deep_features(image_path, model)\n",
    "    \n",
    "    color_features.append(color_hist)\n",
    "    deep_features.append(deep_feat)\n",
    "    image_paths.append(image_path)\n",
    "\n",
    "color_features = np.array(color_features)\n",
    "deep_features = np.array(deep_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\.conda\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "# Combine features (you can choose to use only color or deep features or both)\n",
    "features = np.hstack([color_features, deep_features])\n",
    "\n",
    "# Normalize features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "# Clustering\n",
    "num_clusters = 6  # Choose the number of clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "labels = kmeans.fit_predict(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for clusters and move images\n",
    "output_folder = 'h:\\\\Yehmh\\\\DNDF\\\\101_1_focus\\\\202404_101_seg_images_known_clustered'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    cluster_folder = os.path.join(output_folder, f'cluster_{i}')\n",
    "    if not os.path.exists(cluster_folder):\n",
    "        os.makedirs(cluster_folder)\n",
    "\n",
    "for label, image_path in zip(labels, image_paths):\n",
    "    image_name = os.path.basename(image_path)\n",
    "    cluster_folder = os.path.join(output_folder, f'cluster_{label}')\n",
    "    cv2.imwrite(os.path.join(cluster_folder, image_name), cv2.imread(image_path))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
